{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de853cbb",
   "metadata": {
    "id": "YQvxPDWQDahl"
   },
   "source": [
    "# HW2 (due 9/12) \n",
    "\n",
    "## Global CO2 concentration prediction and practice with scikit-learn [100pt]\n",
    "\n",
    "In class on Wednesday we showed that we can build predictive models for the northern hemisphere monthly average temperature. We achieved a MAE of about 0.5 C.\n",
    "\n",
    "You're going to help me:\n",
    "* Fit and predict the CO2 emissions from the Mauna Loa observatory in Hawaii\n",
    "* analyze the temperature anomaly (temperature variation compared to the monthly average) instead of the absolute temperature\n",
    "* use time series splits to analyze your model\n",
    "* plot the temperature and your best fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633c041",
   "metadata": {
    "id": "scEB7e1nIGGN"
   },
   "source": [
    "## Data download\n",
    "\n",
    "Go to the Mauna Loa data website and find the link to the \"Mauna Loa CO2 weekly mean and historical comparisons\" text or csv file. Download it with wget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a083d229",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMZMxnH-IBe4",
    "outputId": "6cd4d228-6ea4-429f-be0c-a68b5c441da7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79fd8435",
   "metadata": {
    "id": "M-bb_vFjImJF"
   },
   "source": [
    "## Load and visualize the data\n",
    "\n",
    "First, load the data with pandas. You will probably have to change the column names and the number of rows that are skipped compared to the example from class. Depending on whether you download the csv or the txt file you may also have to change delim_whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8774df9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "vqu_0oM5JHcU",
    "outputId": "623b5de5-d8e8-4632-d00e-7e7ee0995637"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6ae4424",
   "metadata": {},
   "source": [
    "Now, plot the CO2 concentration in ppm vs the time (the decimal column in the sheet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c571cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "QA-_Lt8GJdGB",
    "outputId": "b7ed72ec-73ba-466a-a86b-055a65515423"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10560e50",
   "metadata": {},
   "source": [
    "## Filter the data\n",
    "\n",
    "Note that some of the data is reported as -999.99. Those are days when there was no data at Mauna Loa for various reasons. Filter the dataframe to only include rows with positive ppm measurements. Repeat the plot from above to confirm the data looks good now!\n",
    "\n",
    "`````{seealso}\n",
    "https://www.google.com/search?q=pandas+filter+values+greater+than\n",
    "`````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440157d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a189ec0",
   "metadata": {},
   "source": [
    "## Train/val-test split\n",
    "\n",
    "To start, split your data into train/val (90%) and test (10%). Use `sklearn.model_selection.train_test_split` like we did in class. Make sure you don't shuffle when you do it, so that the test data is the most recent 10% of the data!\n",
    "\n",
    "`````{tip}\n",
    "`sklearn.model_selection.train_test_split` can split pandas dataframes directly!\n",
    "`````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b30b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27332c33",
   "metadata": {
    "id": "YLZHcggdKwBP",
    "tags": []
   },
   "source": [
    "# Your first scikit-learn model\n",
    "\n",
    "Scikit-learn can handle all of the things we talked about in class! \n",
    "* Take data and featurizing it\n",
    "* Implement and fit a machine learning model\n",
    "* Create various train/test splits\n",
    "* Calculate the average MAE/RMSE of the splits\n",
    "\n",
    "To implement this, let's use a linear model with polynomial features, like we had in class!\n",
    "\n",
    "`````{tip}\n",
    "Helpful resources!\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit\n",
    "* https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html#sphx-glr-auto-examples-model-selection-plot-underfitting-overfitting-py\n",
    "`````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a9fcf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# We expect a dataframe df_trainval generated above that contains the train and validation data\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m df_train, df_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(df_trainval, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Make a pipeline where we first generate quadratic polynomial features from the time data\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# then fit using linear regression\u001b[39;00m\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m make_pipeline(PolynomialFeatures(\u001b[38;5;241m2\u001b[39m), LinearRegression())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# This is the scikit-learn equivalent way of doing what we did in class. \n",
    "# I've include the code here to get you started. Look through the links above \n",
    "# for documentation on each of the pieces!\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# We expect a dataframe df_trainval generated above that contains the train and validation data\n",
    "df_train, df_val = train_test_split(df_trainval, test_size=0.1, shuffle=False)\n",
    "\n",
    "# Make a pipeline where we first generate quadratic polynomial features from the time data\n",
    "# then fit using linear regression\n",
    "model = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "\n",
    "# Evaluate the model by generate 5 different train/val splits using TimseSeriesSplit,\n",
    "# fitting the model from above on each train, and evaluating the MAE for the validation in each\n",
    "cross_validate(\n",
    "    model,\n",
    "    df_train[\"decimal\"].values.reshape(-1, 1), # The date in decimal format, X\n",
    "    df_train[\"ppm\"].values, # the CO2 concentration in ppm, y\n",
    "    cv=TimeSeriesSplit(),\n",
    "    scoring=[\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a69936",
   "metadata": {},
   "source": [
    "## Underfitting/overfitting\n",
    "\n",
    "Vary the degree of the polynomial features above, and find the degree that minimized the mean absolute error on the final train/val split. Plot the MAE as a function of the polynomial degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e277066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6469bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2274d19a",
   "metadata": {},
   "source": [
    "## Visualize your best model\n",
    "\n",
    "Now that you've optimized the degree of the polynomial to be most predictive for the train/val splits you identified, let's see how it does on the test data you set aside earlier!\n",
    "\n",
    "Make a plot with plotly that shows:\n",
    "* The train/val data and test concentration data\n",
    "* The model you identified above, fitted on all of the train/val data and predicting the test date.\n",
    "Include predictions for the next 5 years. Do these seem reasonable to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fb7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a47366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92ba809f",
   "metadata": {},
   "source": [
    "## Sources of bias and limitations\n",
    "\n",
    "Discuss potential sources of bias or difficulties with this data? Is it possible to predict CO2 concentrations in the future without knowing if the world will take drastic action on CO2 emissions? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0fbc61",
   "metadata": {},
   "source": [
    "## Bonus [10 pt]\n",
    "\n",
    "We used quite simple features, and most likely your best fit has none of the annual cyclic variation present in the original dataset. \n",
    "\n",
    "Try incorporating strategies from one of these:\n",
    "* Periodic spline features (https://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html#periodic-splines)\n",
    "* https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html#sphx-glr-auto-examples-applications-plot-cyclical-feature-engineering-py\n",
    "\n",
    "To see if you can improve on the fit above. What's the lowest MAE you can obtain using the time series splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b924057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst,ipynb",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "source_map": [
   15,
   29,
   35,
   45,
   51,
   60,
   64,
   73,
   83,
   85,
   95,
   99,
   119,
   145,
   151,
   155,
   157,
   168,
   172,
   174,
   180,
   192
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}