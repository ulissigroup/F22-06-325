{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "677cb285-1d09-4e3f-8b1b-60d3fceaef77",
   "metadata": {},
   "source": [
    "```{margin} Adaptation!\n",
    "Some of this homework was inspired by or uses content from Prof. AJ Medford (GTech)'s lectures for ChBE4745: https://github.com/medford-group/data_analytics_ChE\n",
    "\n",
    "The dataset came from Dow Chemicals and released publicly as part of Prof. Medford's class. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7465b94a-f0a7-437a-92a3-d8b5aca63b19",
   "metadata": {},
   "source": [
    "# HW5 (due Monday 10/10 noon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a590a-5ee7-4f79-aa28-00eea469d7f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dow chemical process [100 pts]\n",
    "\n",
    "We're going to use the same Dow process dataset that you used for the last homework and in class. You're going to use what we learned this week to fit neural networks to the dataset, and use dimensionality reduction to improve your previous fits. I think this homework should take less time than normal since I know you all are very busy with your projects!\n",
    "\n",
    "We'll use the same code to load the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06448503-e2fd-4665-a001-5f325fdf0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel('impurity_dataset-training.xlsx')\n",
    "\n",
    "def is_real_and_finite(x):\n",
    "    if not np.isreal(x):\n",
    "        return False\n",
    "    elif not np.isfinite(x):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "all_data = df[df.columns[1:]].values #drop the first column (date)\n",
    "numeric_map = df[df.columns[1:]].applymap(is_real_and_finite)\n",
    "real_rows = numeric_map.all(axis=1).copy().values #True if all values in a row are real numbers\n",
    "X = np.array(all_data[real_rows,:-5], dtype='float') #drop the last 5 cols that are not inputs\n",
    "y = np.array(all_data[real_rows,-3], dtype='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd356aad-f129-44fd-a5e9-04254791ab72",
   "metadata": {},
   "source": [
    "## Train/validation/test split (same as HW4, copy/paste from solutions if you want)\n",
    "\n",
    "Split the dataset into an 80/10/10 train/val/test split. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b73e7-69d0-4097-8030-e81173a34a19",
   "metadata": {},
   "source": [
    "## Supervised regression with PCA with two components\n",
    "\n",
    "Use PCA like we did in class to generate the first two principal components using the training dataset (`X_train`). Use these as features as inputs for your best model from HW4. Calculate the validation error, and compare to your results from HW4.\n",
    "\n",
    "`````{tip}\n",
    "If you're not sure which model to use, you're welcome to use the HW4 solutions which will be posted on Wednesday!), or just use the random forest regressor from sklearn.\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d6777-616b-4f29-bfb0-6b1997598fcb",
   "metadata": {},
   "source": [
    "## Supervised regression with PCA with multiple components\n",
    "\n",
    "Try varying the number of components in PCA from 1 to 10. What's the best validation error you can achieve? Make a plot of validation error (y) vs the number of components (x)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e5fe6-38e3-4f52-9f7d-5ba4b620afb9",
   "metadata": {},
   "source": [
    "## Neural network with three PCA components\n",
    "\n",
    "In class we saw that three PCA components explained most of the data. Generate the first three PCA components, and fit a neural network using MLPRegressor with 2 layers of 10 hidden nodes each. Report your validation error.\n",
    "\n",
    "````{tip}\n",
    "The MLPRegressor documentation is your friend! \n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b149f0-62d9-4241-ba4e-8a9b4dbcb69b",
   "metadata": {},
   "source": [
    "## Varying neural network choices\n",
    "\n",
    "Try varying the number of hidden nodes, the number of layers, and the activation function. Describe the effects you see. \n",
    "\n",
    "What's the best validation error you can achieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e86871-4cb1-4d47-b987-49d5676c574f",
   "metadata": {},
   "source": [
    "## Polynomial features with LASSO\n",
    "\n",
    "Using polynomials up to second order, fit a LASSO model. Print the validation MAE and make a parity plot for your model compared to the experiments!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f8026-e3ae-48b5-82a2-cf500ec4f682",
   "metadata": {},
   "source": [
    "## Pick your best model from above and evaluate your final impurity error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4b57e-4636-41b7-aff1-ef3b7c0ea710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
