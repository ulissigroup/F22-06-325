{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c65c6d08-f832-4b8e-a920-94e943105ff0",
   "metadata": {},
   "source": [
    "`````{note}\n",
    "This lecture is going to:\n",
    "* Review what we mean by features in machine learning models\n",
    "* Demonstrate polynomial fits for a noisy test function with known structure\n",
    "* Formalize our idea of under/over fitting and show how model capacity influences train and validation errors\n",
    "* Introduce regularization as an approach to reduce the train/validation gap and overfitting in models with many features\n",
    "`````\n",
    "\n",
    "`````{seealso}\n",
    "* https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737fc47d-152a-4950-a4a7-c531e74ef451",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Capacity, Overfitting, Regularization, and Ridge/LASSO\n",
    "\n",
    "We're now at the point where we may have many features in a dataset, or where we want to generate many features to build predictive models. We need ways to generalize this process, and control how many features are used. \n",
    "\n",
    "As a reminder, we're currently interested in solving supervised regression problems of the form:\n",
    "\\begin{align*}\n",
    "\\hat{y}=f(\\mathbf{X})\n",
    "\\end{align*}\n",
    "where \n",
    "* $\\hat{y}$ is a vector of outputs (one per data point)\n",
    "* $\\mathbf{X}$ is a 2D array of features (one row per data point, one column per feature)\n",
    "\n",
    "We're only going to use linear regression models in today's lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca85397e-c74d-48c9-8e41-2d716dc84bfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test function (Himmelblau's function)\n",
    "\n",
    "Let's start with the special function we used for the optimization lecture\n",
    "\\begin{align}\n",
    "f(x, y) = (x^2+y-11)^2+(x+y^2-7)^2\n",
    "\\end{align}\n",
    "For clarity, I'm going to write this as \n",
    "\\begin{align}\n",
    "y=f(x_0, x_1) &= (x_0^2+x_2-11)^2+(x_0+x_1^2-7)^2\\\\\n",
    "&=x_0^4+x_1^4+2x_0x_1^2+2x_1x_0^2-21x_0^2-13x_1^2-14x_0-22x_1+170\n",
    "\\end{align}\n",
    "where y is the output/label, and $x_0,x_1$ are potential features (among many that we could choose)! This is a nice test function since it's analytical and is polynomial. If we try to find polynomial features of $x_0,x_1$, we should recover this form. \n",
    "\n",
    "```{seealso}\n",
    "https://en.wikipedia.org/wiki/Himmelblau%27s_function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777a098-1164-4fc6-99d8-05512fd45eea",
   "metadata": {},
   "source": [
    "First, let's define the range of $x_1,x_2$ values we're interested in plotting over, and turn them into a 2D grid like we did in the optimization lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae3f70-35f7-46d2-81a4-ae39fb6fc5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x1range = np.linspace(-5, 5)\n",
    "x2range = np.linspace(-5, 5)\n",
    "\n",
    "# Make 2d arrays for all the unique values of x_1/x_2\n",
    "x1grid, x2grid = np.meshgrid(x1range, x2range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560303a-d27b-47ce-a78a-f4acb895a0cd",
   "metadata": {},
   "source": [
    "Now, let's define a function to return Himmelblau's function, plus a little bit of random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeb7381-9463-4cac-b5b9-e276e3e2d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def himmelblau_with_noise(x1, x2, noise=0.1, seed=42):\n",
    "\n",
    "    # Set the numpy random seed so the results are reproducible\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Generate the himmelblau function\n",
    "    himmelblau = (x1**2 + x2 - 11) ** 2 + (x1 + x2**2 - 7) ** 2\n",
    "\n",
    "    # Multiple by a bit of Gaussian random noise and return\n",
    "    noise = np.random.normal(loc=1, scale=noise, size=x1.shape)\n",
    "    return himmelblau * noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c7ee90-9f0d-4ac8-9a68-faea1b91a358",
   "metadata": {},
   "source": [
    "Finally, let's plot the function without noise, and add points for 20 random points in that space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68fe54-0c66-4277-b186-741865268712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Surface(\n",
    "            x=x1range, y=x2range, z=himmelblau_with_noise(x1grid, x2grid, noise=0)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Generate 20 samples from the noisy Himmelblau function\n",
    "nsamples = 20\n",
    "X = np.random.uniform(low=-5, high=5, size=(nsamples, 2))\n",
    "y = himmelblau_with_noise(X[:, 0], X[:, 1])\n",
    "\n",
    "# Plot with plotly\n",
    "fig.add_scatter3d(\n",
    "    x=X[:, 0], y=X[:, 1], z=y, mode=\"markers\", marker=dict(size=6, color=\"#00FF00\")\n",
    ")\n",
    "fig.update_layout(autosize=False, width=800, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b489ca17-d297-4146-944b-b37b099a1c18",
   "metadata": {},
   "source": [
    "## Data generation: Generate 60 random samples and a random 60/20/20 train/val/test split\n",
    "\n",
    "Before we do anything, we need to separate our data into train/val/test splits so that we don't overfit and we have some idea of how predictive our model is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bdb76b-d7ee-4839-aa63-c812264e5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Helper function to generate train/val/test splits for\n",
    "def generate_trainvaltest_data(nsamples):\n",
    "\n",
    "    # Sample npoints random x1/x2 values\n",
    "    np.random.seed(42)\n",
    "    X = np.random.uniform(low=-5, high=5, size=(nsamples, 2))\n",
    "\n",
    "    # Evaluate the function\n",
    "    y = himmelblau_with_noise(X[:, 0], X[:, 1])\n",
    "\n",
    "    # Generate the train/val/test splits\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=True, random_state=42\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_trainval, y_trainval, test_size=0.25, shuffle=True, random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = generate_trainvaltest_data(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d824bb-64d7-4bec-a014-4d1dce7ca4ed",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab783bb9-7620-4bbb-b903-93a872fdab84",
   "metadata": {},
   "source": [
    "### Base case (linear model with $x_0$, $x_1$ as the only the features)\n",
    "\n",
    "Our goal will be to find the polynomial features that make this an easy function to fit. Before we do something interesting, let's start with the simplest thing we can try: a linear function using just $x_0$ and $x_1$ as features.\n",
    "\n",
    "We'll use scikit-learn now that we've seen an example through the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1667fa79-0acb-4197-ad1e-0a3ef6735b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "mae = mean_absolute_error(y_val, model.predict(X_val))\n",
    "rmse = mean_squared_error(y_val, model.predict(X_val)) ** 0.5\n",
    "\n",
    "print(\n",
    "    f\"The MAE for the linear fit is {mae:0.2f}, compared to a standard deviation of {y_val.std():0.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"The RMSE for the linear fit is {rmse:0.2f}, compared to a standard deviation of {y_val.std():0.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33001826-c46e-472d-8d42-aefbfd91620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_predict_on_grid(model, x1grid, x2grid):\n",
    "    # An sklearn pipeline or model will expect to predict on a NxM array,\n",
    "    # where N is the number of data points and M is the number of features\n",
    "    # This helper function will take two\n",
    "    X = np.hstack((x1grid.reshape((-1, 1)), (x2grid.reshape((-1, 1)))))\n",
    "    y = model.predict(X)\n",
    "\n",
    "    return y.reshape(x1grid.shape)\n",
    "\n",
    "\n",
    "# Test the function on the grid we were predicting on!\n",
    "sklearn_predict_on_grid(model, x1grid, x2grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3240d4a1-ac14-490c-b5d1-8abf51cda6f9",
   "metadata": {},
   "source": [
    "Now, let's plot the linear fit, as well as the train and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3f0ff-1f68-4d3d-b470-b512c673852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Plot the fitted model\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Surface(\n",
    "            x=x1range, y=x2range, z=sklearn_predict_on_grid(model, x1grid, x2grid)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot the train data\n",
    "fig.add_scatter3d(\n",
    "    x=X_train[:, 0],\n",
    "    y=X_train[:, 1],\n",
    "    z=y_train,\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=6, color=\"#00FF00\"),\n",
    "    name=\"Train Data\",\n",
    ")\n",
    "# Plot the validation data\n",
    "fig.add_scatter3d(\n",
    "    x=X_val[:, 0],\n",
    "    y=X_val[:, 1],\n",
    "    z=y_val,\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=6, color=\"#000000\"),\n",
    "    name=\"Validation Data\",\n",
    ")\n",
    "fig.update_layout(autosize=False, width=800, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec2286-d838-4d2b-9b9e-8931431ca6d7",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the fitted model\n",
    "fig = go.Figure(data=[go.Scatter(x=y_val, y=model.predict(X_val), mode=\"markers\")])\n",
    "\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=y_val.min(),\n",
    "    y0=y_val.min(),\n",
    "    x1=y_val.max(),\n",
    "    y1=y_val.max(),\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Actual Value\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Predicted Value\",\n",
    ")\n",
    "\n",
    "# Set the plot size\n",
    "fig.update_layout(autosize=False, width=800, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7339f9-ff2b-4911-9237-9ea33368e9bc",
   "metadata": {},
   "source": [
    "### Polynomial case (linear model with polynomial features)\n",
    "\n",
    "You saw in homework 2 that we can ask scikit-learn to generate polynomial features as part of a pipeline. Let's use that to generate all of the features up to the fourth power to fit. We know that fourth order is the right place to stop because we know the functional form, so otherwise this would be something we play around with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577333e0-9d05-464b-a0fc-d3614642df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "model = LinearRegression()\n",
    "model = make_pipeline(PolynomialFeatures(4), LinearRegression(fit_intercept=False))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "mae = mean_absolute_error(y_val, model.predict(X_val))\n",
    "rmse = mean_squared_error(y_val, model.predict(X_val)) ** 0.5\n",
    "\n",
    "print(\n",
    "    f\"The MAE for the polynomial fit is {mae:0.2f}, compared to a standard deviation of {y_val.std():0.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"The RMSE for the polynomial fit is {rmse:0.2f}, compared to a standard deviation of {y_val.std():0.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e8c626-d8b0-45c4-8335-ff1acdca27ea",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Plot the fitted model\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Surface(\n",
    "            x=x1range, y=x2range, z=sklearn_predict_on_grid(model, x1grid, x2grid)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Surface(\n",
    "            x=x1range, y=x2range, z=sklearn_predict_on_grid(model, x1grid, x2grid)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot the train data\n",
    "fig.add_scatter3d(\n",
    "    x=X_train[:, 0],\n",
    "    y=X_train[:, 1],\n",
    "    z=y_train,\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=6, color=\"#00FF00\"),\n",
    "    name=\"Train Data\",\n",
    ")\n",
    "# Plot the validation data\n",
    "fig.add_scatter3d(\n",
    "    x=X_val[:, 0],\n",
    "    y=X_val[:, 1],\n",
    "    z=y_val,\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=6, color=\"#000000\"),\n",
    "    name=\"Validation Data\",\n",
    ")\n",
    "fig.update_layout(autosize=False, width=800, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6e6a6-9fe7-407a-933d-209d6c83bb1b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Parity plot!\n",
    "fig = go.Figure(data=[go.Scatter(x=y_val, y=model.predict(X_val), mode=\"markers\")])\n",
    "\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=y_val.min(),\n",
    "    y0=y_val.min(),\n",
    "    x1=y_val.max(),\n",
    "    y1=y_val.max(),\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Actual Value\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Predicted Value\",\n",
    ")\n",
    "\n",
    "# Set the plot size\n",
    "fig.update_layout(autosize=False, width=800, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315272c-d440-4a49-9ed1-87dc25adf8c4",
   "metadata": {},
   "source": [
    "Before we move on, let's do a quick check to see how the polynomial features compare with what we know to be true for the real model!\n",
    "\n",
    "We can get descriptive names for the features with `model[0].get_feature_names_out()` and we can get the fitted coefficients with `model[1].coef_`.\n",
    "\n",
    "````{tip}\n",
    "If you're ever confused about what methods/functions/attributes that are available on an object, try `dir(object)`! I use this all the time because I can't remember all of the methods for every type of model. \n",
    "\n",
    "Try it with `dir(model[0])`!\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7c996-2881-47b0-9d0e-6fa20ab46e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param, name in zip(model[1].coef_, model[0].get_feature_names_out()):\n",
    "    print(f\"The coefficient for {name} is {param:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a51ec-42ab-4b56-a141-d25b158dc440",
   "metadata": {},
   "source": [
    "Remember the real functional form was $f(x_0, x_1) = x_0^4+x_1^4+2x_0x_1^2+2x_1x_0^2-21x_0^2-13x_1^2-14x_0-22x_1+170$. Most of the coefficients are pretty good! There are a few that are close to zero but not quite. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5333c217-f8b8-479e-866a-e394b883166f",
   "metadata": {},
   "source": [
    "## Model capacity and under/over-fitting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be04bd1c-e787-4a5e-b1cf-d3268a6edebe",
   "metadata": {},
   "source": [
    "Let's see how the number of polynomial features affects the fit for both the train and validation data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbe75da-4de5-4118-9462-d780956c0c3e",
   "metadata": {},
   "source": [
    "With 60 samples, this actually looks pretty good! Let's see how our model works with varying model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e2b7ee-2fef-4cdd-b73a-70469809a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = generate_trainvaltest_data(60)\n",
    "\n",
    "train_rmse = {}\n",
    "val_rmse = {}\n",
    "for degree in range(10):\n",
    "\n",
    "    # Make and fit a model with the appropriate degree!\n",
    "    model = LinearRegression()\n",
    "    model = make_pipeline(\n",
    "        PolynomialFeatures(degree), LinearRegression(fit_intercept=False)\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the RMSE results in the dictionaries above\n",
    "    train_rmse[degree] = mean_squared_error(y_train, model.predict(X_train)) ** 0.5\n",
    "    val_rmse[degree] = mean_squared_error(y_val, model.predict(X_val)) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ffac91-0261-488e-b91f-09bcb23f0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the generalization gap!\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(\n",
    "            x=list(train_rmse.keys()), y=list(train_rmse.values()), name=\"Training\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.add_scatter(x=list(val_rmse.keys()), y=list(val_rmse.values()), name=\"Validation\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Model Capacity (Polynomial Order)\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    range=[0, 300],\n",
    "    title_text=\"Model Fit (RMSE)\",\n",
    ")\n",
    "\n",
    "# Set the plot size\n",
    "fig.update_layout(autosize=False, width=800, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501487f-893b-4319-b94d-9e91278b8557",
   "metadata": {},
   "source": [
    "There's a couple of interesting things here:\n",
    "* The validation curve is usually above the training curve since the model hasn't seen that data before\n",
    "* The training curve monotonically decreases with increasing capacity for these features and model\n",
    "* The validation curve goes through a minimum at polynomial order 4, then stays roughly flat, then shoots up\n",
    "\n",
    "\n",
    "````{note}\n",
    "We call the gap between the training and validation results the **generalization gap**, since it shows how the models are able to generalize to the data in the validation set. Good features/models will have small generalization gaps, and by making smart modeling choices we can reduce it!\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f7521f-421e-4713-a479-76fb0c080c79",
   "metadata": {},
   "source": [
    "### Practice\n",
    "\n",
    "Repeat the above with more than 60 data points. How do the results change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c2d66-b142-47c4-a1c7-08ab0feea3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "631c45fd-369e-461f-b8d3-6436891d817c",
   "metadata": {},
   "source": [
    "## Reducing the generalization gap\n",
    "\n",
    "To summarize the above:\n",
    "* We can generate many features which may be useful in building a model\n",
    "* Generating features that are actually used in the model can be very helpful\n",
    "* If we generate too many features, we can actually make the model worse for predicting new data\n",
    "\n",
    "We have a couple options:\n",
    "* Tune the number or type of features being generated to minimize the validation error\n",
    "* Change the model or features\n",
    "* Change how we train the model (which we'll talk about here!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e1c9a-70b5-4d23-ab07-61d6c9b89c61",
   "metadata": {},
   "source": [
    "### No regularization (linear regression)\n",
    "\n",
    "As a reminder from the previous lecture on regression, we can think of linear regression as finding the parameters $\\theta_i$ by minimizing the loss ($\\mathcal{L}$) sum squared errors:\n",
    "\\begin{align*}\n",
    "\\min_{\\theta}\\mathcal{L} =\\min_{\\theta}  \\left(y_i-\\hat{y}_i\\right)^2\n",
    "\\end{align*}\n",
    "To convince ourselves that this is true, let's do a quick demonstration using minimize to fit the loss function explicitly and plot the coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a85d30-fcf7-456c-be0f-66440cbdc33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "# Sum squared error loss function!\n",
    "def loss(theta, X, y):\n",
    "    y_pred = X @ theta\n",
    "    loss = sum((y - y_pred) ** 2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Linear regression fit using scipy.optimize.minimize\n",
    "features = PolynomialFeatures(4).fit_transform(X_train)\n",
    "sol = minimize(\n",
    "    loss,\n",
    "    np.ones(features.shape[1]),\n",
    "    args=(features, y_train),\n",
    ")\n",
    "print(sol.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf2e99-9e65-477a-8ca9-1c2f4d729b01",
   "metadata": {},
   "source": [
    "Now, let's do the same thing with scikit-learn. We should get the same results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f561d7-5225-4314-8f44-649b1deca822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression fit using sklearn\n",
    "model = LinearRegression()\n",
    "model = make_pipeline(PolynomialFeatures(4), LinearRegression(fit_intercept=False))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print the coefficients from sklearn, showing you get the same answer using either method!\n",
    "print(model[1].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08baa101-d32e-48d6-902c-145dcc125297",
   "metadata": {},
   "source": [
    "These coefficients are exactly the same as the custom model we optimized. As a final step and for comparison with the next steps, we'll repeat the plot from above to see how the train/validation errors scale with maximum polynomial degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f98d2b-c647-43e3-9ab6-940406f6145d",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the generalization gap!\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(\n",
    "            x=list(train_rmse.keys()), y=list(train_rmse.values()), name=\"Training\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.add_scatter(x=list(val_rmse.keys()), y=list(val_rmse.values()), name=\"Validation\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Model Capacity (Polynomial Order)\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    range=[0, 300],\n",
    "    title_text=\"Model Fit (RMSE)\",\n",
    ")\n",
    "\n",
    "# Set the plot size\n",
    "fig.update_layout(autosize=False, width=600, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bf176-8398-4ba3-82ee-f94ba74e57f6",
   "metadata": {},
   "source": [
    "### L2 regularization (ridge regression, or Tikhonov regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e119a1ec-ac54-46d7-adf9-caeffb755542",
   "metadata": {},
   "source": [
    "\n",
    "Regularization refers to a small change in how we fit our models. We're not going to change the model at all - we're only going to train the fitting procedure. Specifically, we're going to add a term to our loss function that includes the absolute size of the fitted parameters. \n",
    "\n",
    "One of the most common types of regularization is L2 regularization. When this is applied to a linear model, it's called ridge regression. This approach is often effective at reducing the train/validation gap:\n",
    "\\begin{align*}\n",
    "\\min_{\\theta}\\mathcal{L} =\\min_{\\theta} \\left[ \\left(y_i-\\hat{y}_i\\right)^2 + \\alpha \\sum_j \\theta_j^2\\right]\n",
    "\\end{align*}\n",
    "where $\\theta_j$ are the model parameters, and $\\alpha$ is a parameter that we can adjust to control the regularization.\n",
    "\n",
    "`````{note}\n",
    "* **Regularization:** Strategy to reduce the train/validation gap\n",
    "* **L2 regularization:** Otherwise known as Tikhonov regularization, or Ridge regression if the model is linear\n",
    "* $\\alpha$: an empirical parameter that controls how strong the regularization is \n",
    "`````\n",
    "\n",
    "`````{warning}\n",
    "Large  $\\alpha$ effectively reduce the model capacity. If you make the $\\alpha$ too large it will hurt the training errors!\n",
    "`````\n",
    "\n",
    "To demonstrate this we'll again do the fit using a custom loss function, and using the `Ridge` model from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4228af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "# Sum squared error loss function!\n",
    "def loss(theta, X, y, alpha=1):\n",
    "    y_pred = X @ theta\n",
    "    loss = sum((y - y_pred) ** 2) + alpha * (theta**2.0).sum()\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Linear regression fit using scipy.optimize.minimize, showing you get the same answer using either method!\n",
    "sol = minimize(\n",
    "    loss,\n",
    "    np.ones(model[1].coef_.shape),\n",
    "    args=(PolynomialFeatures(4).fit_transform(X_train), y_train, 1),\n",
    ")\n",
    "print(sol.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec47824-b401-4ac7-a6a5-1c89166476bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Linear Regression fit using sklearn\n",
    "model = LinearRegression()\n",
    "model = make_pipeline(PolynomialFeatures(4), Ridge(fit_intercept=False))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print the coefficients from sklearn, showing you get the same answer using either method!\n",
    "print(model[1].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d5d49-cd2a-400b-9d63-20768c76268b",
   "metadata": {},
   "source": [
    "Same coefficients either way! Let's see how this affects the model performance as the number of features increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd97f2f-0684-4723-84b9-5301c2fa858f",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = generate_trainvaltest_data(60)\n",
    "\n",
    "train_rmse = {}\n",
    "val_rmse = {}\n",
    "for degree in range(10):\n",
    "\n",
    "    # Make and fit a model with the appropriate degree!\n",
    "    model = LinearRegression()\n",
    "    model = make_pipeline(\n",
    "        PolynomialFeatures(degree), Ridge(fit_intercept=False, alpha=1)\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the RMSE results in the dictionaries above\n",
    "    train_rmse[degree] = mean_squared_error(y_train, model.predict(X_train)) ** 0.5\n",
    "    val_rmse[degree] = mean_squared_error(y_val, model.predict(X_val)) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd64ce-e7f4-48fe-b64a-a76506603bd7",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the generalization gap!\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(\n",
    "            x=list(train_rmse.keys()), y=list(train_rmse.values()), name=\"Training\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.add_scatter(x=list(val_rmse.keys()), y=list(val_rmse.values()), name=\"Validation\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Model Capacity (Polynomial Order)\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    range=[0, 300],\n",
    "    title_text=\"Model Fit (RMSE)\",\n",
    ")\n",
    "\n",
    "# Set the plot size\n",
    "fig.update_layout(autosize=False, width=600, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39884af9-cc04-4e68-8b01-81f82b0a35cf",
   "metadata": {},
   "source": [
    "### Practice: Vary the alpha parameter and describe the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47739a0-7068-4593-91e2-f42fd9eaffe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47faa835-f67f-4561-b6f4-632881423bf8",
   "metadata": {},
   "source": [
    "### L1 regularization (LASSO)\n",
    "\n",
    "Another common regularization strategy is L1 regularization. When applied to linear models this is called LASSO regression.\n",
    "\\begin{align*}\n",
    "\\min_{\\theta}\\mathcal{L} =\\min_{\\theta} \\left[ \\frac{\\left(y_i-\\hat{y}_i\\right)^2}{2N} + \\alpha \\sum_j |\\theta_j|\\right]\n",
    "\\end{align*}\n",
    "where $\\theta_j$ are the model parameters, and $\\alpha$ is a parameter that we can adjust to control the regularization, and N is the number of training data. The LASSO model has the interesting property that, after minimization, many of the parameters tend to be 0. Non-zero elements will tell you which features are important. LASSO can be used as a feature selection strategy!\n",
    "\n",
    "`````{note}\n",
    "* **Feature selection:** A step in an ML process to identify which features are most important and only use those in the final model\n",
    "* **LASSO:** L1 regularization applied to linear regression. LASSO tends to set some parameters equal to 0!\n",
    "`````\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eddf17-f1b3-46da-a778-c4b79494f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "# Sum squared error loss function!\n",
    "def loss(theta, X, y, alpha=1):\n",
    "    y_pred = X @ theta\n",
    "\n",
    "    # Loss from https://github.com/scikit-learn/scikit-learn/blob/36958fb24/sklearn/linear_model/_coordinate_descent.py#L1134\n",
    "    loss = sum((y - y_pred) ** 2) / 2 / len(y) + alpha * np.abs(theta).sum()\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Linear regression fit using scipy.optimize.minimize, showing you get the same answer using either method!\n",
    "features = PolynomialFeatures(4).fit_transform(X_train)\n",
    "sol = minimize(\n",
    "    loss,\n",
    "    np.zeros(features.shape[1]),\n",
    "    args=(features, y_train, 1),\n",
    ")\n",
    "print(sol.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412c741-0202-45b7-9e85-c282fe4f2a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Linear Regression fit using sklearn\n",
    "model = Lasso()\n",
    "model = make_pipeline(PolynomialFeatures(4), Lasso(fit_intercept=False))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print the coefficients from sklearn, showing you get the same answer using either method!\n",
    "print(model[1].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7092aa25-4d8d-4411-8de4-3ab0d9a4ee39",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = generate_trainvaltest_data(60)\n",
    "\n",
    "train_rmse = {}\n",
    "val_rmse = {}\n",
    "for degree in range(14):\n",
    "\n",
    "    # Make and fit a model with the appropriate degree!\n",
    "    model = LinearRegression()\n",
    "    model = make_pipeline(\n",
    "        PolynomialFeatures(degree),\n",
    "        Lasso(fit_intercept=False, alpha=0.1, max_iter=100000),\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the RMSE results in the dictionaries above\n",
    "    train_rmse[degree] = mean_squared_error(y_train, model.predict(X_train)) ** 0.5\n",
    "    val_rmse[degree] = mean_squared_error(y_val, model.predict(X_val)) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e2bf5-5e87-4c7b-b471-13c65c6b7918",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the generalization gap!\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(\n",
    "            x=list(train_rmse.keys()), y=list(train_rmse.values()), name=\"Training\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.add_scatter(x=list(val_rmse.keys()), y=list(val_rmse.values()), name=\"Validation\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Model Capacity (Polynomial Order)\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    range=[0, 300],\n",
    "    title_text=\"Model Fit (RMSE)\",\n",
    ")\n",
    "\n",
    "# Set the plot size\n",
    "fig.update_layout(autosize=False, width=600, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ab65a-2052-4f18-b098-cbba371b1e4a",
   "metadata": {},
   "source": [
    "Notice the validation error, especially with a very large model, is significantly better here. There's some variability depending on how the model is fit and the initial parameters used before the minimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c75152-ec58-4a55-9263-2792eaa2c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[1].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7598f60-b35f-4551-b482-0a30b17377f1",
   "metadata": {},
   "source": [
    "As one final check, let's see how the results for parameter coefficients compare with the known Himmelblau function parameters from above!\n",
    "\\begin{align}\n",
    "y=f(x_0, x_1) &= (x_0^2+x_2-11)^2+(x_0+x_1^2-7)^2\\\\\n",
    "&=x_0^4+x_1^4+2x_0x_1^2+2x_1x_0^2-21x_0^2-13x_1^2-14x_0-22x_1+170\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6fb682-691c-4849-b77b-cf3635688d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param, name in zip(model[-1].coef_, model[0].get_feature_names_out()):\n",
    "    if np.abs(param) > 0.01:\n",
    "        print(f\"The coefficient for {name} is {param:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f57ccf-3d5d-42de-b83e-4d2237145718",
   "metadata": {},
   "source": [
    "### Practice: Vary the alpha parameter and describe the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7cc6f0-e193-4fc8-93ea-4f58dc64c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "078ef93f-fa86-489a-9d3f-b02e4c3a9bc9",
   "metadata": {},
   "source": [
    "`````{note}\n",
    "Summary!\n",
    "* We can add many possible features to our ML models\n",
    "* We should be careful about how our model performs for train/validation as we increase the model complexity or increase the number of features\n",
    "* We can reduce the gap between train and validation errors by adding parameter regularization to the loss function\n",
    "* LASSO can be used to identify important features by forcing unimportant feature weights to zero!\n",
    "`````"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
