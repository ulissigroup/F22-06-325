{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bf2a79e-3f2b-4a4d-ba31-c64b05b7248f",
   "metadata": {},
   "source": [
    "# Validation and Test Splits\n",
    "\n",
    "In most of the examples and homeworks so far we've used cross validation with three splits:\n",
    "* **Train:** The data we train candidate models on\n",
    "* **Validation:** The data we use to choose the best model\n",
    "* **Test:** The data we use to evaluate our final model\n",
    "\n",
    "The splitting strategy should be related to the actual engineering challenge (if you want a model that can interpolate among data, randomly sample; if you want a model that can extrapolate to the future, split on time, etc).\n",
    "\n",
    "If you are pretty sure of the model and hyperparameters (model settings) that you will use and the dataset is very small, it's sometimes ok to just use a train/test split. It is pretty common in research literature to see models with just train/test splits. \n",
    "\n",
    "However, you should be extremely careful when doing this. To demonstrate the dangers let's consider a toy problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6639f449-bfd6-4b09-9228-8845d43030d6",
   "metadata": {},
   "source": [
    "## Toy problem: random number features and target\n",
    "\n",
    "We're going to use a very simple dataset - 20 random numbers chosen by randomly sampling from a Gaussian/normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef3df6-e247-438b-92bb-d5d54a38d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate N random data points with M random features\n",
    "N = 20\n",
    "M = 10000\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.normal(size=(N, M))\n",
    "y = np.random.normal(size=(N,))\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e15dd5-cb17-4de9-b597-ee21275f6406",
   "metadata": {},
   "source": [
    "Now, let's split this dataset into a 60/20/20 train/val/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a9f4f-ee99-4b89-b7c5-b836237ffd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valtest, y_train, y_valtest = train_test_split(X, y, train_size=0.6)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, train_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12417c0-a499-4979-8db0-801e6254cdbe",
   "metadata": {},
   "source": [
    "I'm going to propose a very simple model with 4 parameters. I will take "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fadad7-50b8-40f5-8903-89efa49a0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "class SimpleModel:\n",
    "    def __init__(self, column=1):\n",
    "        self.column = column\n",
    "        return\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.LR = LinearRegression()\n",
    "        self.LR.fit(X[:, self.column : self.column + 1], y)\n",
    "\n",
    "        # Do nothing!\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.LR.predict(X[:, self.column : self.column + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba008e56-fe33-47b3-95ae-4f285d2c37f2",
   "metadata": {},
   "source": [
    "Now, let's fit this model and score it on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c57c8-8a34-4290-98f6-08df5684877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "SM = SimpleModel()\n",
    "SM.fit(X_train, y_train)\n",
    "\n",
    "MAE = mean_absolute_error(SM.predict(X_val), y_val)\n",
    "print(f\"The model MAE is {MAE:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d85ec2-b00d-40b4-9d3f-8494d4b9a80e",
   "metadata": {},
   "source": [
    "So far so good! Now, let's find the column that minimizes the validation error by doing some simple feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d749233-5354-4bf5-b36d-ae407dc514c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_column = -1\n",
    "best_MAE = 10\n",
    "\n",
    "for column in range(M):\n",
    "    SM = SimpleModel(column=column)\n",
    "    SM.fit(X_train, y_train)\n",
    "    MAE = mean_absolute_error(SM.predict(X_val), y_val)\n",
    "\n",
    "    if MAE < best_MAE:\n",
    "        best_column = column\n",
    "        best_MAE = MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df677a7d-8ff3-472f-9a5d-dec779734c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The best column is {best_column} with a validation MAE of {best_MAE:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d8c4b4-7006-4b43-b028-94869e7670b3",
   "metadata": {},
   "source": [
    "Awesome! We found a model with a validation error of 0.21 eV! This is exciting. Finally, let's check our test error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5552c-2bab-4675-b068-d3ac98d131d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(SM.predict(X_test), y_test)\n",
    "print(f\"The model MAE is {MAE:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf972cd8-ae97-457b-9e6a-a36b13d77322",
   "metadata": {},
   "source": [
    "This is VERY different; what happened here? Which of these numbers do you trust more? \n",
    "\n",
    "Let's visualize what happened here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a0fa3-48d2-4ca4-85ea-d0a10ec4743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Plot with plotly!\n",
    "fig = go.Figure()\n",
    "fig.add_scatter(\n",
    "    x=X_train[:, best_column : best_column + 1].reshape((-1,)),\n",
    "    y=y_train,\n",
    "    mode=\"markers\",\n",
    "    name=\"Training Data\",\n",
    ")\n",
    "fig.add_scatter(\n",
    "    x=X_val[:, best_column : best_column + 1].reshape((-1,)),\n",
    "    y=y_val,\n",
    "    mode=\"markers\",\n",
    "    name=\"Validation Data\",\n",
    ")\n",
    "fig.add_scatter(\n",
    "    x=X_test[:, best_column : best_column + 1].reshape((-1,)),\n",
    "    y=y_test,\n",
    "    mode=\"markers\",\n",
    "    name=\"Test Data\",\n",
    ")\n",
    "\n",
    "# Fit the best model we found and plot it\n",
    "SM = SimpleModel(column=best_column)\n",
    "SM.fit(X_train, y_train)\n",
    "\n",
    "fig.add_scatter(\n",
    "    x=X[:, best_column : best_column + 1].reshape((-1,)),\n",
    "    y=SM.predict(X),\n",
    "    name=\"Best Fit\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6976f65f-ea3f-4e1c-8d19-525ee3736df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
